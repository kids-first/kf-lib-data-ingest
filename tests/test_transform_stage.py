
import pytest
import pandas as pd
from copy import deepcopy

from kf_lib_data_ingest.common.errors import InvalidIngestStageParameters
from kf_lib_data_ingest.common.concept_schema import (
    CONCEPT,
    DELIMITER,
    UNIQUE_ID_ATTR,
    concept_from,
    unique_key_composition
)
from kf_lib_data_ingest.etl.transform.common import (
    _add_unique_key_cols,
    VALUE_DELIMITER
)
from kf_lib_data_ingest.common.constants import *


@pytest.fixture(scope='function')
def df():
    """
    Reusable test dataframe
    """
    return pd.DataFrame([{CONCEPT.PARTICIPANT.ID: 'P1',
                          CONCEPT.BIOSPECIMEN.ID: 'B1',
                          CONCEPT.PARTICIPANT.RACE: RACE.WHITE},
                         {CONCEPT.PARTICIPANT.ID: 'P1',
                          CONCEPT.BIOSPECIMEN.ID: 'B2',
                          CONCEPT.PARTICIPANT.RACE: RACE.WHITE},
                         {CONCEPT.PARTICIPANT.ID: 'P2',
                          CONCEPT.BIOSPECIMEN.ID: 'B3',
                          CONCEPT.PARTICIPANT.RACE: RACE.ASIAN}])


def test_invalid_run_parameters(transform_stage, **kwargs):
    """
    Test running transform with invalid run params
    """

    # Bad keys
    with pytest.raises(InvalidIngestStageParameters):
        transform_stage.run({i: 'foo' for i in range(5)})

    # Bad values
    with pytest.raises(InvalidIngestStageParameters):
        transform_stage.run({'foor': ('bar', None) for i in range(5)})


def test_read_write(transform_stage, df):
    """
    Test TransformStage.read_output/write_output
    """
    extract_output = {'extract_config_url': ('source_url', df)}

    # Transform outputs json
    output = transform_stage.run(extract_output)
    recycled_output = transform_stage.read_output()

    for target_entity, data in output.items():
        assert target_entity in recycled_output
        other_data = recycled_output[target_entity]
        # Compare using DataFrames
        assert pd.DataFrame(other_data).equals(pd.DataFrame(data))


def test_unique_keys(df):
    """
    Test that transform stage correctly iterates over each mapped df and
    inserts a unique key column for each concept.

    Most concept's unique keys are composed of just the ID attribute. These
    are standard unique keys
    """

    # 3 Columns before
    assert 3 == len(df.columns)
    df = _add_unique_key_cols(df, unique_key_composition)

    # 3 original + 2 unique key cols for the concepts
    assert 5 == len(df.columns)

    # Num of distinct concepts shouldn't change
    concepts = set([concept_from(col) for col in df.columns])
    assert 2 == len(concepts)

    # Check values
    for concept_name in concepts:
        ukey_col = f'{concept_name}{DELIMITER}{UNIQUE_ID_ATTR}'
        id_col = f'{concept_name}{DELIMITER}ID'
        assert ukey_col in df.columns
        assert df[id_col].equals(df[ukey_col])


def test_compound_unique_keys():
    """
    Test that compound unique keys are autogenerated.

    These are non-standard unique keys for concepts that do not
    have an ID attribute to use as a unique key. These concepts have unique
    keys which are composed of several other concept attributes.
    """
    df = pd.DataFrame([{CONCEPT.PARTICIPANT.ID: 'P1',
                        CONCEPT.BIOSPECIMEN.ID: 'B1',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'},
                       {CONCEPT.PARTICIPANT.ID: 'P1',
                        CONCEPT.BIOSPECIMEN.ID: 'B2',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'},
                       {CONCEPT.PARTICIPANT.ID: 'P2',
                        CONCEPT.BIOSPECIMEN.ID: 'B3',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'}])

    # 3 columns before
    assert 3 == len(df.columns)
    df = _add_unique_key_cols(df, unique_key_composition)
    # 3 original + 3 unique key columns + 1 for the compound concept
    assert 7 == len(df.columns)
    # 4 distinct concepts should exist now (1 new one is a compound concept)
    concepts = set([concept_from(col) for col in df.columns])
    assert 4 == len(concepts)

    # Check values
    for concept_name in concepts:
        ukey_col = f'{concept_name}{DELIMITER}{UNIQUE_ID_ATTR}'
        id_col = f'{concept_name}{DELIMITER}ID'
        assert ukey_col in df.columns

        if concept_name == CONCEPT.BIOSPECIMEN_GENOMIC_FILE._CONCEPT_NAME:
            col1 = CONCEPT.BIOSPECIMEN.UNIQUE_KEY
            col2 = CONCEPT.GENOMIC_FILE.UNIQUE_KEY

            def func(row):
                return (
                    row[ukey_col].split(VALUE_DELIMITER)[0] == row[col1] and
                    row[ukey_col].split(VALUE_DELIMITER)[1] == row[col2]
                )

            assert df.apply(lambda row: func(row), axis=1).all()

        else:
            assert df[id_col].equals(df[ukey_col])


def test_unique_key_w_optional():
    """
    Test unique key construction for concept whose unique key has both
    required components and optional components
    """
    df = pd.DataFrame({
        CONCEPT.PARTICIPANT.ID: ['p1', 'p2', 'p3'],
        CONCEPT.DIAGNOSIS.NAME: ['cold', 'flu', 'something'],
        CONCEPT.DIAGNOSIS.EVENT_AGE_DAYS: [20, 30, 40]
    })
    df = _add_unique_key_cols(df, unique_key_composition)

    # Check for unique key column names and values
    for ukey_col in [CONCEPT.PARTICIPANT.UNIQUE_KEY,
                     CONCEPT.DIAGNOSIS.UNIQUE_KEY]:
        assert ukey_col in df.columns

    def func(row):
        ukey = VALUE_DELIMITER.join(
            [str(row[CONCEPT.PARTICIPANT.ID]),
             str(row[CONCEPT.DIAGNOSIS.NAME]),
             str(row[CONCEPT.DIAGNOSIS.EVENT_AGE_DAYS])])
        return row[ukey_col] == ukey

    assert df.apply(lambda row: func(row), axis=1).all()


def test_no_key_comp_defined():
    """
    Test concept in concept schema does not have a unique key comp defined
    """
    df = pd.DataFrame([{CONCEPT.PARTICIPANT.ID: 'P1',
                        CONCEPT.BIOSPECIMEN.ID: 'B1',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'},
                       {CONCEPT.PARTICIPANT.ID: 'P1',
                        CONCEPT.BIOSPECIMEN.ID: 'B2',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'},
                       {CONCEPT.PARTICIPANT.ID: 'P2',
                        CONCEPT.BIOSPECIMEN.ID: 'B3',
                        CONCEPT.GENOMIC_FILE.ID: 'G1'}])

    # No key composition defined for concept
    del unique_key_composition[CONCEPT.PARTICIPANT._CONCEPT_NAME]
    with pytest.raises(AssertionError) as e:
        _add_unique_key_cols(df, unique_key_composition)
        assert 'key composition not defined' in str(e)


def test_unique_key_to_target_id(caplog, transform_stage):
    """
    Test kf_lib_data_ingest.etl.transform.transform.unique_keys_to_target_ids
    """
    id_cache = {
        'biospecimen': {
            'b2': 'BS_00000002'
        }
    }
    data_in = {
        'biospecimen':
        [
            {'id': 'b1',  # should resolve to None
             'links': {
                 'participant_id': 'p1',  # should resolve to None
                 'sequencing_center_id': None
             }},
            {'id': 'b2',  # should resolve to BS_00000002
             'links': {
                 'participant_id': 'p1',  # should resolve to None
                 'sequencing_center_id': None
             }}
        ],
        'participant':
        [
            {'id': 'p1',  # should resolve to None
             'links': {
                 'study_id': 's1'  # should resolve to None
             }}
        ]
    }
    data_out = transform_stage._unique_keys_to_target_ids(id_cache,
                                                          deepcopy(data_in))

    for target_concept, instances in data_out.items():
        for i, instance in enumerate(instances):
            if target_concept not in id_cache:
                assert (instance['id']['source'] ==
                        data_in[target_concept][i]['id'])
                assert instance['id']['target'] is None
            else:
                source_id = instance['id']['source']
                assert source_id == data_in[target_concept][i]['id']
                expected = id_cache[target_concept].get(source_id, None)
                assert instance['id']['target'] == expected

    # No cache exists yet
    data_out = transform_stage._unique_keys_to_target_ids(
        {}, deepcopy(data_in))
    assert 'Creating new UID cache' in caplog.text
